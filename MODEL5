import 
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
from sklearn.preprocessing import StandardScaler
import logging
import warnings
warnings.filterwarnings('ignore')

# 设置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bike_prediction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def add_time_features(df):
    """添加增强的时间特征"""
    df['hour'] = df['date'].dt.hour
    df['weekday'] = df['date'].dt.weekday
    df['month'] = df['date'].dt.month
    df['is_weekend'] = (df['weekday'] >= 5).astype(int)
    
    # 添加周期性特征
    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)
    df['month_sin'] = np.sin(2 * np.pi * df['month']/12)
    df['month_cos'] = np.cos(2 * np.pi * df['month']/12)
    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday']/7)
    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday']/7)
    
    return df

def add_lag_features(df, group_col='counter_id', target_col='log_bike_count'):
    """添加多个滞后特征和统计特征"""
    lags = [1, 2, 3, 24, 48]
    windows = [6, 12, 24, 48]
    
    for lag in lags:
        df[f'lag_{lag}'] = df.groupby(group_col)[target_col].shift(lag)
    
    for window in windows:
        df[f'rolling_mean_{window}h'] = df.groupby(group_col)[target_col].transform(
            lambda x: x.rolling(window).mean())
        df[f'rolling_std_{window}h'] = df.groupby(group_col)[target_col].transform(
            lambda x: x.rolling(window).std())
    
    return df

def evaluate_predictions(y_true, y_pred):
    """评估预测结果"""
    metrics = {
        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
        'mae': mean_absolute_error(y_true, y_pred),
        'r2': r2_score(y_true, y_pred)
    }
    return metrics

try:
    logger.info("开始数据加载和预处理...")
    
    # 定义数据路径
    base_path = Path("D:/X-HEC/python for data science/pre/msdb-2024")

    # 加载数据
    train = pd.read_parquet(base_path / "train.parquet")
    test = pd.read_parquet(base_path / "final_test.parquet")
    external = pd.read_csv(base_path / "external.csv")

    # 将日期列转换为 datetime 类型
    train['date'] = pd.to_datetime(train['date'])
    test['date'] = pd.to_datetime(test['date'])
    external['date'] = pd.to_datetime(external['date'], format='%Y/%m/%d %H:%M')

    # 添加时间特征
    logger.info("添加时间特征...")
    train = add_time_features(train)
    test = add_time_features(test)

    # 计算安装时间（单位：天）
    train['installation_days'] = (train['date'] - pd.to_datetime(train['counter_installation_date'])).dt.days
    test['installation_days'] = (test['date'] - pd.to_datetime(test['counter_installation_date'])).dt.days

    # 合并天气数据
    train = train.merge(external, on='date', how='left')
    test = test.merge(external, on='date', how='left')

    # 天气相关特征
    weather_features = [
        't', 'vv', 'rr3', 'n', 'pres', 'tend24', 'raf10',
        'td', 'ww', 'nbas', 'hbas', 'rafper', 'rr1', 'rr6', 'rr12', 'rr24'
    ]

    # 填充天气数据的缺失值
    for feature in weather_features:
        train[feature] = train[feature].fillna(train[feature].mean())
        test[feature] = test[feature].fillna(test[feature].mean())

    # 标准化所有天气特征
    scaler = StandardScaler()
    train[weather_features] = scaler.fit_transform(train[weather_features])
    test[weather_features] = scaler.transform(test[weather_features])

    # 添加滞后特征
    logger.info("添加滞后特征...")
    train = add_lag_features(train)
    
    # 填充滞后特征的缺失值
    lag_cols = [col for col in train.columns if 'lag_' in col or 'rolling_' in col]
    train[lag_cols] = train[lag_cols].fillna(0)

    # 特征选择
    features = [
        'hour', 'weekday', 'month', 'is_weekend', 'installation_days',
        'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'weekday_sin', 'weekday_cos'
    ] + weather_features + lag_cols

    target = 'log_bike_count'

    # 模型训练
    logger.info("开始模型训练...")
    X = train[features]
    y = train[target]

    # 时间序列交叉验证
    tscv = TimeSeriesSplit(n_splits=5)
    
    # LightGBM 参数
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'random_state': 42
    }

    cv_scores = []
    
    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):
        logger.info(f"训练折次 {fold}/5...")
        
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        
        lgb_train = lgb.Dataset(X_train, y_train)
        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)
        
        model = lgb.train(
            params,
            lgb_train,
            num_boost_round=1000,
            valid_sets=[lgb_val],
            callbacks=[lgb.early_stopping(50, verbose=False)]
        )
        
        # 验证集评估
        val_pred = model.predict(X_val)
        metrics = evaluate_predictions(y_val, val_pred)
        cv_scores.append(metrics)
        
        logger.info(f"Fold {fold} - RMSE: {metrics['rmse']:.4f}, MAE: {metrics['mae']:.4f}, R2: {metrics['r2']:.4f}")

    # 计算平均评估指标
    avg_metrics = {
        metric: np.mean([score[metric] for score in cv_scores]) 
        for metric in cv_scores[0].keys()
    }
    logger.info(f"平均评估指标 - RMSE: {avg_metrics['rmse']:.4f}, MAE: {avg_metrics['mae']:.4f}, R2: {avg_metrics['r2']:.4f}")

    # 测试集预测
    logger.info("开始测试集预测...")
    
    # 初始化测试集的滞后特征
    for col in lag_cols:
        test[col] = 0.0

    # 按计数器ID进行预测
    unique_counters = test['counter_id'].unique()
    
    for counter_id in unique_counters:
        test_counter = test[test['counter_id'] == counter_id].copy()
        train_counter = train[train['counter_id'] == counter_id].copy()
        
        # 初始化滞后值
        last_values = {
            f'lag_{lag}': float(train_counter['log_bike_count'].iloc[-lag]) 
            if len(train_counter) >= lag else 0.0 
            for lag in [1, 2, 3, 24, 48]
        }
        
        # 初始化滚动统计值
        rolling_stats = {
            window: {
                'values': list(train_counter['log_bike_count'].iloc[-window:]) if len(train_counter) >= window else [],
                'mean': float(train_counter['log_bike_count'].iloc[-window:].mean()) if len(train_counter) >= window else 0.0,
                'std': float(train_counter['log_bike_count'].iloc[-window:].std()) if len(train_counter) >= window else 0.0
            }
            for window in [6, 12, 24, 48]
        }
        
        # 逐步预测
        for i in range(len(test_counter)):
            # 更新滞后特征
            for lag, value in last_values.items():
                test_counter.loc[test_counter.index[i], lag] = value
            
            # 更新滚动统计特征
            for window, stats in rolling_stats.items():
                test_counter.loc[test_counter.index[i], f'rolling_mean_{window}h'] = stats['mean']
                test_counter.loc[test_counter.index[i], f'rolling_std_{window}h'] = stats['std']
            
            # 预测
            features_values = test_counter.loc[test_counter.index[i], features].values.reshape(1, -1)
            predicted_value = model.predict(features_values)[0]
            test_counter.loc[test_counter.index[i], 'log_bike_count'] = predicted_value
            
            # 更新滞后值
            for lag in sorted([1, 2, 3, 24, 48], reverse=True):
                if lag == 1:
                    last_values[f'lag_{lag}'] = predicted_value
                else:
                    last_values[f'lag_{lag}'] = last_values[f'lag_{lag-1}']
            
            # 更新滚动统计值
            for window, stats in rolling_stats.items():
                stats['values'].append(predicted_value)
                if len(stats['values']) > window:
                    stats['values'].pop(0)
                stats['mean'] = np.mean(stats['values'])
                stats['std'] = np.std(stats['values']) if len(stats['values']) > 1 else 0.0
        
        # 更新测试集预测结果
        test.loc[test['counter_id'] == counter_id, 'log_bike_count'] = test_counter['log_bike_count']

    # 转换回实际计数
    test['bike_count'] = np.exp(test['log_bike_count'])

    # 保存结果
    logger.info("保存预测结果...")
    submission = test[['counter_id', 'counter_name', 'site_id', 'site_name', 'date', 'log_bike_count']]
    submission.to_csv(base_path / "submission.csv", index=False)

    logger.info("预测完成，结果已保存为 submission.csv 文件")

except Exception as e:
    logger.error(f"发生错误: {str(e)}")
    raise