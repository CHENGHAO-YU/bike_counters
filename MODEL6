import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import VotingRegressor
import warnings
warnings.filterwarnings('ignore')

# 定义数据路径
base_path = Path("D:/X-HEC/python for data science/pre/msdb-2024")

# 加载数据
print("加载数据...")
train = pd.read_parquet(base_path / "train.parquet")
test = pd.read_parquet(base_path / "final_test.parquet")
external = pd.read_csv(base_path / "external.csv")

# 将日期列转换为 datetime 类型
train['date'] = pd.to_datetime(train['date'])
test['date'] = pd.to_datetime(test['date'])
external['date'] = pd.to_datetime(external['date'], format='%Y/%m/%d %H:%M')

# 添加时间特征
def add_time_features(df):
    df['hour'] = df['date'].dt.hour
    df['weekday'] = df['date'].dt.weekday
    df['month'] = df['date'].dt.month
    df['is_weekend'] = (df['weekday'] >= 5).astype(int)
    
    # 添加周期性特征
    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)
    df['month_sin'] = np.sin(2 * np.pi * df['month']/12)
    df['month_cos'] = np.cos(2 * np.pi * df['month']/12)
    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday']/7)
    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday']/7)
    
    return df

print("添加时间特征...")
train = add_time_features(train)
test = add_time_features(test)

# 计算安装时间（单位：天）
train['installation_days'] = (train['date'] - pd.to_datetime(train['counter_installation_date'])).dt.days
test['installation_days'] = (test['date'] - pd.to_datetime(test['counter_installation_date'])).dt.days

# 合并天气数据
print("合并天气数据...")
train = train.merge(external, on='date', how='left')
test = test.merge(external, on='date', how='left')

# 天气相关特征
weather_features = [
    't', 'vv', 'rr3', 'n', 'pres', 'tend24', 'raf10',
    'td', 'ww', 'nbas', 'hbas', 'rafper', 'rr1', 'rr6', 'rr12', 'rr24'
]

# 填充天气数据的缺失值
for feature in weather_features:
    train[feature] = train[feature].fillna(train[feature].mean())
    test[feature] = test[feature].fillna(test[feature].mean())

# 标准化所有天气特征
print("标准化特征...")
scaler = StandardScaler()
train[weather_features] = scaler.fit_transform(train[weather_features])
test[weather_features] = scaler.transform(test[weather_features])

# 添加滞后特征和统计特征
def add_lag_features(df, group_col='counter_id', target_col='log_bike_count'):
    lags = [1, 2, 3, 24, 48]
    windows = [6, 12, 24, 48]
    
    for lag in lags:
        df[f'lag_{lag}'] = df.groupby(group_col)[target_col].shift(lag)
    
    for window in windows:
        df[f'rolling_mean_{window}h'] = df.groupby(group_col)[target_col].transform(
            lambda x: x.rolling(window).mean())
        df[f'rolling_std_{window}h'] = df.groupby(group_col)[target_col].transform(
            lambda x: x.rolling(window).std())
    
    return df

def prepare_lag_features(df, is_train=True):
    if is_train:
        return add_lag_features(df)
    else:
        # 为测试集创建空的滞后特征列
        lags = [1, 2, 3, 24, 48]
        windows = [6, 12, 24, 48]
        
        for lag in lags:
            df[f'lag_{lag}'] = 0
        
        for window in windows:
            df[f'rolling_mean_{window}h'] = 0
            df[f'rolling_std_{window}h'] = 0
        
        return df

# 为训练集和测试集准备特征
print("准备滞后特征...")
train = prepare_lag_features(train, is_train=True)
test = prepare_lag_features(test, is_train=False)

# 初始化测试集的log_bike_count列
test['log_bike_count'] = 0

# 填充训练集滞后特征的缺失值
lag_cols = [col for col in train.columns if 'lag_' in col or 'rolling_' in col]
train[lag_cols] = train[lag_cols].fillna(0)

# 特征选择
features = [
    'hour', 'weekday', 'month', 'is_weekend', 'installation_days',
    'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'weekday_sin', 'weekday_cos'
] + weather_features + lag_cols

target = 'log_bike_count'

# 定义评估函数
def evaluate_model(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return rmse, mae, r2

# LightGBM 参数
lgb_params = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.01,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'max_depth': 8,
    'min_child_samples': 20,
    'reg_alpha': 0.1,
    'reg_lambda': 0.1,
    'random_state': 42
}

# XGBoost 参数
xgb_params = {
    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'learning_rate': 0.01,
    'max_depth': 8,
    'min_child_weight': 3,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'gamma': 0.1,
    'reg_alpha': 0.1,
    'reg_lambda': 0.1,
    'random_state': 42
}

# CatBoost 参数
cat_params = {
    'iterations': 1000,
    'learning_rate': 0.01,
    'depth': 8,
    'l2_leaf_reg': 3,
    'bagging_temperature': 1,
    'random_seed': 42,
    'verbose': False
}

# 训练集准备
X = train[features]
y = train[target]

# 时间序列交叉验证
tscv = TimeSeriesSplit(n_splits=5)

# 存储每个模型的验证分数
lgb_scores = []
xgb_scores = []
cat_scores = []

# 用于存储最佳模型
best_lgb_model = None
best_xgb_model = None
best_cat_model = None
best_score = float('inf')

print("开始训练模型...")

# 训练和评估模型
for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):
    print(f"训练折次 {fold}/5")
    
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
    
    # LightGBM
    lgb_train = lgb.Dataset(X_train, y_train)
    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)
    lgb_model = lgb.train(
        lgb_params,
        lgb_train,
        num_boost_round=1000,
        valid_sets=[lgb_val],
        callbacks=[lgb.early_stopping(50, verbose=False)]
    )
    lgb_pred = lgb_model.predict(X_val)
    lgb_rmse = np.sqrt(mean_squared_error(y_val, lgb_pred))
    lgb_scores.append(lgb_rmse)
    
    # XGBoost
    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)
    dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)
    
    evallist = [(dval, 'eval')]
    xgb_model = xgb.train(
        xgb_params,
        dtrain,
        num_boost_round=1000,
        evals=evallist,
        early_stopping_rounds=50,
        verbose_eval=False
    )
    xgb_pred = xgb_model.predict(dval)
    xgb_rmse = np.sqrt(mean_squared_error(y_val, xgb_pred))
    xgb_scores.append(xgb_rmse)
    
    # CatBoost
    cat_model = CatBoostRegressor(**cat_params)
    cat_model.fit(
        X_train, y_train,
        eval_set=(X_val, y_val),
        early_stopping_rounds=50,
        verbose=False
    )
    cat_pred = cat_model.predict(X_val)
    cat_rmse = np.sqrt(mean_squared_error(y_val, cat_pred))
    cat_scores.append(cat_rmse)
    
    # 保存最佳模型
    current_score = (lgb_rmse + xgb_rmse + cat_rmse) / 3
    if current_score < best_score:
        best_score = current_score
        best_lgb_model = lgb_model
        best_xgb_model = xgb_model
        best_cat_model = cat_model

# 打印每个模型的平均分数
print(f"LightGBM average RMSE: {np.mean(lgb_scores):.4f}")
print(f"XGBoost average RMSE: {np.mean(xgb_scores):.4f}")
print(f"CatBoost average RMSE: {np.mean(cat_scores):.4f}")

# 计算模型权重
weights = [
    1 / np.mean(lgb_scores),
    1 / np.mean(xgb_scores),
    1 / np.mean(cat_scores)
]
weights = np.array(weights) / sum(weights)

print("开始测试集预测...")

# 对测试集进行递归预测
for counter_id in test['counter_id'].unique():
    print(f"处理计数器 {counter_id}")
    test_counter = test[test['counter_id'] == counter_id].copy()
    train_counter = train[train['counter_id'] == counter_id].copy()
    
    # 初始化历史值
    history = list(train_counter['log_bike_count'].iloc[-48:]) if len(train_counter) >= 48 else [0] * 48
    
    for i in range(len(test_counter)):
        # 更新滞后特征
        for lag in [1, 2, 3, 24, 48]:
            test_counter.iloc[i, test_counter.columns.get_loc(f'lag_{lag}')] = history[-lag]
        
        # 更新滚动统计特征
        for window in [6, 12, 24, 48]:
            recent_values = history[-window:]
            test_counter.iloc[i, test_counter.columns.get_loc(f'rolling_mean_{window}h')] = np.mean(recent_values)
            test_counter.iloc[i, test_counter.columns.get_loc(f'rolling_std_{window}h')] = np.std(recent_values) if len(recent_values) > 1 else 0
        
        # 获取当前样本的特征并进行预测
        current_features = test_counter.iloc[i][features].values.reshape(1, -1)
        
        # 各模型预测
        lgb_pred = best_lgb_model.predict(current_features)[0]
        
        # XGBoost预测
        dtest = xgb.DMatrix(current_features, feature_names=features)
        xgb_pred = best_xgb_model.predict(dtest)[0]
        
        # CatBoost预测
        cat_pred = best_cat_model.predict(current_features)[0]
        
        # 加权平均预测
        prediction = weights[0] * lgb_pred + weights[1] * xgb_pred + weights[2] * cat_pred
        
        # 更新历史记录
        history.append(prediction)
        if len(history) > 48:
            history.pop(0)
        
        # 保存预测结果
        test_counter.iloc[i, test_counter.columns.get_loc('log_bike_count')] = prediction
    
    # 更新主测试集
    test.loc[test['counter_id'] == counter_id, 'log_bike_count'] = test_counter['log_bike_count']

# 转换回实际计数
test['bike_count'] = np.exp(test['log_bike_count'])

# 保存结果
print("保存预测结果...")
submission = test[['counter_id', 'counter_name', 'site_id', 'site_name', 'date', 'log_bike_count']]
submission.to_csv(base_path / "submission.csv", index=False)

print("预测完成，结果已保存为 submission.csv 文件")