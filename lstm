import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
from keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import TimeSeriesSplit

# 设置简短运转标志
short_run = False  # 设为 False 以使用完整数据集和模型配置

# 定义数据路径
base_path = Path("D:/X-HEC/python for data science/pre/msdb-2024")

# 加载数据
train = pd.read_parquet(base_path / "train.parquet")
test = pd.read_parquet(base_path / "final_test.parquet")
external = pd.read_csv(base_path / "external.csv", parse_dates=['date'])

# 简短运转时减少数据量
if short_run:
    top_n_counters = 10
    unique_counters = train['counter_id'].value_counts().index[:top_n_counters]
    train = train[train['counter_id'].isin(unique_counters)]
    test = test[test['counter_id'].isin(unique_counters)]

    # 进一步减少每个计数器的数据量
    train = train.groupby('counter_id').head(50)  # 每个计数器取前50条记录
    test = test.groupby('counter_id').head(24)    # 测试集中每个计数器取前24小时的数据

# 将日期列转换为 datetime 类型
train['date'] = pd.to_datetime(train['date'])
test['date'] = pd.to_datetime(test['date'])

# 添加时间特征
def add_time_features(df):
    df['hour'] = df['date'].dt.hour
    df['weekday'] = df['date'].dt.weekday
    df['month'] = df['date'].dt.month
    df['is_weekend'] = (df['weekday'] >= 5).astype(int)
    return df

train = add_time_features(train)
test = add_time_features(test)

# 计算安装时间（单位：天）
train['installation_days'] = (train['date'] - pd.to_datetime(train['counter_installation_date'])).dt.days
test['installation_days'] = (test['date'] - pd.to_datetime(test['counter_installation_date'])).dt.days

# 合并天气数据
train = train.merge(external, on='date', how='left')
test = test.merge(external, on='date', how='left')

# 所有天气相关特征（包括新增特征）
weather_features = [
    't', 'vv', 'rr3', 'n', 'pres', 'tend24', 'raf10',
    'td', 'ww', 'rafper', 'rr1', 'rr6', 'rr12', 'rr24'
]

# 填充新增天气数据的缺失值
for feature in weather_features:
    # 确保数据按日期时间排序
    train = train.sort_values(by=['counter_id', 'date'])
    test = test.sort_values(by=['counter_id', 'date'])

    # 使用 ffill 和 bfill 填充缺失值
    train[feature] = train.groupby('counter_id')[feature].fillna(method='ffill').fillna(method='bfill')
    test[feature] = test.groupby('counter_id')[feature].fillna(method='ffill').fillna(method='bfill')

    # 插值填充
    def interpolate_group(group):
        group = group.reset_index().set_index('date')  # 设置 date 为索引
        interpolated = group.interpolate(method='time', limit_direction='both')
        return interpolated

    train[[feature]] = train.set_index('date').groupby('counter_id', group_keys=False).apply(
        lambda g: interpolate_group(g[[feature]])
    ).reset_index(level=0, drop=True)

    test[[feature]] = test.set_index('date').groupby('counter_id', group_keys=False).apply(
        lambda g: interpolate_group(g[[feature]])
    ).reset_index(level=0, drop=True)

    # 如果仍有缺失值，可以用均值填充
    train[feature] = train[feature].fillna(train[feature].mean())
    test[feature] = test[feature].fillna(test[feature].mean())

    # 重置索引以确保后续操作不受影响
    train = train.reset_index(drop=True)
    test = test.reset_index(drop=True)

# 标准化所有天气特征
scaler = StandardScaler()
train[weather_features] = scaler.fit_transform(train[weather_features])
test[weather_features] = scaler.transform(test[weather_features])

# 添加滞后和滚动特征
train['lag_1'] = train.groupby('counter_id')['log_bike_count'].shift(1)
train['rolling_mean_24h'] = train.groupby('counter_id')['log_bike_count'].transform(lambda x: x.rolling(24).mean())

# 使用 bfill 和 ffill 填充滞后特征的缺失值
train['lag_1'] = train.groupby('counter_id')['lag_1'].fillna(method='ffill').fillna(method='bfill')
train['rolling_mean_24h'] = train.groupby('counter_id')['rolling_mean_24h'].fillna(method='ffill').fillna(method='bfill')

# 最终填充剩余的缺失值
train['lag_1'] = train['lag_1'].fillna(0)
train['rolling_mean_24h'] = train['rolling_mean_24h'].fillna(0)

# 更新特征选择（将新增特征加入到 features 中）
features = [
    'hour', 'weekday', 'month', 'is_weekend', 'installation_days',
    'lag_1', 'rolling_mean_24h',
    # 加入所有天气相关特征
    't', 'vv', 'rr3', 'n', 'pres', 'tend24', 'raf10',
    'td', 'ww', 'rafper', 'rr1', 'rr6', 'rr12', 'rr24'
]
target = 'log_bike_count'

# 创建序列数据
def create_sequences(data, target, time_steps=1):
    xs, ys = [], []
    for i in range(len(data) - time_steps):
        x = data[i:(i + time_steps)]
        y = target[i + time_steps]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

time_steps = 24  # 例如，我们可以选择过去24小时的数据作为时间步

# 准备LSTM所需格式的数据
X_lstm = train[features].values
y_lstm = train[target].values

# 创建序列化数据
X_seq, y_seq = create_sequences(X_lstm, y_lstm, time_steps)

# 重塑输入数据以适应LSTM [samples, time_steps, n_features]
X_seq = X_seq.reshape((X_seq.shape[0], X_seq.shape[1], X_seq.shape[2]))

# 模型训练准备
tscv = TimeSeriesSplit(n_splits=2 if short_run else 5)  # 简短运转时减少分割数

best_rmse = float('inf')
best_model = None

# 使用LSTM
for train_idx, val_idx in tscv.split(X_seq):
    X_train, X_val = X_seq[train_idx], X_seq[val_idx]
    y_train, y_val = y_seq[train_idx], y_seq[val_idx]

    model = Sequential()
    model.add(LSTM(30, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')

    early_stopping = EarlyStopping(monitor='val_loss', patience=2 if short_run else 5, restore_best_weights=True)

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=10 if short_run else 100,  # 简短运转时减少迭代次数
        batch_size=64,
        callbacks=[early_stopping],
        verbose=1 if short_run else 0  # 简短运转时显示输出以监控进度
    )

    y_pred_val = model.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))
    
    print(f"Validation RMSE: {rmse}")
    
    if rmse < best_rmse:
        best_rmse = rmse
        best_model = model

print(f"Best Validation RMSE: {best_rmse}")

def create_sequences(data, targets, time_steps):
    Xs, ys = [], []
    for i in range(len(data) - time_steps):
        v = data[i:(i + time_steps)]
        Xs.append(v)
        ys.append(targets[i + time_steps])
    return np.array(Xs), np.array(ys)

# 测试集预测（非递归预测）
unique_counters = test['counter_id'].unique()

for counter_id in unique_counters:
    print(f"Processing counter_id: {counter_id}")  # 调试信息
    test_counter = test[test['counter_id'] == counter_id].copy()
    train_counter = train[train['counter_id'] == counter_id].copy()

    if not train_counter.empty and len(test_counter) >= time_steps:
        # 初始化滞后特征和滚动平均特征
        last_log_bike_count = train_counter['log_bike_count'].iloc[-time_steps:].values
        
        # 构建初始序列时不包含 lag_1 和 rolling_mean_24h
        base_features = [feat for feat in features if feat not in ['lag_1', 'rolling_mean_24h']]
        initial_train_features_values = train_counter[base_features].iloc[-time_steps:].values
        initial_test_features_values = test_counter[base_features].values[:time_steps]
        
        # 将训练集的最后一个时间步长的历史数据与测试集的前几个时间点结合
        combined_initial_features = np.concatenate([initial_train_features_values, initial_test_features_values], axis=0)[-time_steps:]
        
        # 创建初始序列
        test_X_seq = create_sequences(combined_initial_features.reshape(1, -1, len(base_features)), [0]*len(combined_initial_features), time_steps)[0]

        # 确保 test_X_seq 不为空
        if len(test_X_seq) == 0:
            print(f"No valid sequences found for counter_id: {counter_id}")
            continue
        
        # 初始化 log_bike_count 列
        test_counter['log_bike_count'] = 0.0  # 或者其他合理的默认值

        # 预测初始序列后的所有数据点
        for i in range(len(test_counter) - time_steps):
            # 使用模型预测下一个时间点
            next_pred = best_model.predict(test_X_seq[-1].reshape(1, time_steps, len(base_features)))
            
            # 存储预测结果
            test_counter.loc[test_counter.index[i + time_steps], 'log_bike_count'] = next_pred.flatten()[0]

            # 动态更新滞后特征和滚动平均特征
            if i > 0:  # 只有在至少有一个预测之后才能更新滞后特征
                test_counter.loc[test_counter.index[i + time_steps], 'lag_1'] = next_pred.flatten()[0]
                
                # 更新 rolling_mean_24h 特征
                if i >= 23:  # 确保有足够的历史数据来计算滚动平均
                    rolling_window = test_counter['log_bike_count'].iloc[max(0, i + time_steps - 24):i + time_steps + 1]
                    test_counter.loc[test_counter.index[i + time_steps], 'rolling_mean_24h'] = rolling_window.mean()

            # 更新用于后续预测的特征值
            new_row = test_counter[features].iloc[i + time_steps].values.reshape(1, -1)
            test_X_seq = np.append(test_X_seq, new_row[np.newaxis, :], axis=0)
            test_X_seq = test_X_seq[1:]  # 移除最早的行以保持时间步长不变

    # 对于没有训练数据或者数据不足的情况，设置 log_bike_count 为 0 或其他默认值
    else:
        test_counter['log_bike_count'] = 0.0
    
    # 更新原始测试集中对应计数器的结果
    test.loc[test['counter_id'] == counter_id, 'log_bike_count'] = test_counter['log_bike_count']

# 确保最终结果中存在 log_bike_count 列
if 'log_bike_count' not in test.columns:
    test['log_bike_count'] = 0.0

test['bike_count'] = np.exp(test['log_bike_count'])

# 保存结果
submission = test[['counter_id', 'counter_name', 'site_id', 'site_name', 'date', 'log_bike_count']]
submission.to_csv(base_path / "submission.csv", index=False)

print("预测结果已保存为 submission.csv 文件")